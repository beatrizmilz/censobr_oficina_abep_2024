---
title: "3. Microdados"
from: markdown+emoji
code-annotations: hover
---

# Dados disponíveis no {censobr}

O pacote **{censobr}** disponibiliza microdados da amostra de todas as edições do censo demográfico desde 1970, e em breve também incluirá os dados de 1960 e 2022. A Tabela 1 apresenta abaixo todas as bases de dados do censo que você conseguie acessar com o **{censobr}**.

**Tabela 1. Funções de dados disponíveis no {censobr}**

```{=html}
<!DOCTYPE html>
<html lang="en">
<head>
  <!-- <meta charset="UTF-8"> -->
  
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        table {
            width: 100%;
            border-collapse: collapse;
        }
        table, th, td {
            border: 1px solid black; /* Thicker border for better visibility */
        }
        th, td {
            padding: 10px;
            text-align: center;
        }
    </style>
</head>
<body>

<table border="1" cellpadding="5" cellspacing="0">
  <thead>
    <tr>
      <th rowspan="2">Função</th>
      <th rowspan="2">Origem</th>
      <th rowspan="2">Unidade</th>
      <th rowspan="2">Definição</th>
      <th colspan="6">Disponibilidade</th>
    </tr>
    <tr>
      <th>1960</th>
      <th>70</th>
      <th>80</th>
      <th>91</th>
      <th>2000</th>
      <th>10</th>
      <th>22</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>read_population()</td>
      <td>Amostra</td>
      <td>Microdado</td>
      <td>Lê os microdados de pessoas.</td>
      <td><i>em breve</i></td>
      <td>X</td>
      <td>X</td>
      <td>X</td>
      <td></td>
      <td>X</td>
      <td><i>em breve</i></td>
    </tr>
    <tr>
      <td>read_households()</td>
      <td>Amostra</td>
      <td>Microdado</td>
      <td>Lê os microdados de domicílios.</td>
      <td><i>em breve</i></td>
      <td>X</td>
      <td>X</td>
      <td>X</td>
      <td>X</td>
      <td>X</td>
      <td><i>em breve</i></td>
    </tr>
    <tr>
      <td>read_families()</td>
      <td>Amostra</td>
      <td>Microdado</td>
      <td>Lê os microdados de famílias do censo de 2000.</td>
      <td></td>
      <td></td>
      <td></td>
      <td>X</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>read_emigration()</td>
      <td>Amostra</td>
      <td>Microdado</td>
      <td>Lê os microdados de emigração.</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td>X</td>
      <td></td>
      <td><i>em breve</i></td>
    </tr>
    <tr>
      <td>read_mortality()</td>
      <td>Amostra</td>
      <td>Microdado</td>
      <td>Lê os microdados de mortalidade.</td>
      <td></td>
      <td></td>
      <td></td>
      <td>X</td>
      <td></td>
      <td><i>em breve</i></td>
    </tr>
    <tr>
      <td>read_tracts()</td>
      <td>Universo</td>
      <td>Setor Censitário</td>
      <td>Lê os dados do Universo agregados por setores censitários.</td>
      <td></td>
      <td>X</td>
      <td>X</td>
      <td>X</td>
      <td></td>
      <td>X</td>
      <td>X</td>
    </tr>
  </tbody>
</table>

</body>
</html>
```

Todas as funções de leitura de microdados possuem a mesma esturutra (sintaxe), o que permite o usuário baixar os dados de maneira fácil e intuitiva com um único comando. As funções possuem os seguintes parâmetros:

```{r, eval = FALSE}
read_households(
  year,          # ano de referência
  columns,       # seleciona colunas que devem ser lidas
  add_labels,    # adiciona os 'labels' das variáveis categóricas
  as_data_frame, # retorna resultado como um `Arrow DataSet` ou `data.frame`
  showProgress,  # mostra contagem de download
  cache          # salva arquivo em cache para rapida leitura posteriormente
  )
```


::: {.callout-important appearance="default"}
## Cache local dos dados

A primeira vez que o usuário executa uma função, o **{censobr}** fará o download dos dados e os armazenará localmente numa pasta do pacote. Dessa forma, os dados precisam ser baixados apenas uma vez. Mais informações na seção *Cache de Dados* abaixo.

:::


# Trabalhando com dados maior do que a RAM

![](images/arrow_plus_dplyr.png){width=350 fig-align="right"}
É muito comum que os microdados do censo brasileiro sejam grandes demais para serem carregados na memória RAM dos usuários. Para resolver esse problema, o **{censobr}** foi construído sobre a plataforma [Arrow](https://arrow.apache.org/docs/r/) e arquivos em formato `.parquet`, o que permite que o usuário trabalhe de maneira eficiente até mesmo com bases de dados muito grandes utilizando funções já bem conhecidas do pacote [{dplyr}](https://arrow.apache.org/docs/r/articles/arrow.html#analyzing-arrow-data-with-dplyr).


Vamos então carregas as bibliotecas que vamos precisar e partir para exemplos na prática.


```{r, message = FALSE}
#| label: load-libraries
# carrega bibliotecas
library(censobr)
library(arrow)
library(dplyr)
library(ggplot2)
```


# Dados de população

Neste exemplo, nós vamos criar um gráfico da pirâmica populacional do Brasil no ano de 2010. Primeiro, precisamos usar a função `read_population()` para carregar os microdados de população.


O comportamento padrão das as funções do **{censobr}** é retornar *todas* as variáveis das bases de dados. No entanto, como vamos fazer uma análise simples, o mais eficiente é passarmos um vetor com os nomes das colunas que vamos utilizar (neste caso, as variáveis de região, peso amostral, sexo e idade).

```{r}
#| label: read-population-data
pop <- read_population(
  year = 2010,
  columns = c('name_region', 'V0010', 'V0601', 'V6036'),
  add_labels = 'pt',    # <1>
  showProgress = TRUE
  )

class(pop)

```
1. Adicionando os 'labels' em Português das variáveis categóricas.


Por padrão, a saída da função é um `"arrow_dplyr_query"` ou `"ArrowObject"`. Isso permite que você trabalhe com os dados do censo de maneira super rápida e eficiente, mesmo que a tabela de dados seja grande demais para a memória do seu computador. Ao definir o parâmetro `as_data_frame = TRUE`, a função carregará os dados como um `data.frame` na memória RAM. ***Atenção***: isso pode fazer com que a sessão do R trave em ambientes com restrições computacionais.

Esses outputs podem ser analisados como de maneira similar a como se analisaria um `data.frame` utilizando-se funções do pacote {dplyr}. Uma diferença, no entanto, é que as operações somente são executadas quando o usuário roda a função `dplyr::collect()` 

Aqui, por exemplo, nós visualizamos as primeiras linhas da tabela de dados:

```{r}
#| label: head-population-data
head(pop) |> collect()

```

O próximo passo é criar um variável categória com grupos de idade a cada 5 anos.

```{r}
#| label: create-age-variable
pop <- pop |>
  mutate(
    age_group = dplyr::case_when(
      V6036 <= 04              ~ "00-05",
      V6036 >= 05 & V6036 < 10 ~ "05-10",
      V6036 >= 10 & V6036 < 15 ~ "10-15",
      V6036 >= 15 & V6036 < 20 ~ "15-20",
      V6036 >= 20 & V6036 < 25 ~ "20-25",
      V6036 >= 25 & V6036 < 30 ~ "25-30",
      V6036 >= 30 & V6036 < 35 ~ "30-35",
      V6036 >= 35 & V6036 < 40 ~ "35-40",
      V6036 >= 40 & V6036 < 45 ~ "40-45",
      V6036 >= 45 & V6036 < 50 ~ "45-50",
      V6036 >= 50 & V6036 < 55 ~ "50-55",
      V6036 >= 55 & V6036 < 60 ~ "55-60",
      V6036 >= 60 & V6036 < 65 ~ "60-65",
      V6036 >= 65 & V6036 < 70 ~ "65-70",
      V6036 >= 70              ~ "75+"
      ))

head(pop) |> collect()
```

E em seguida, nós só precisamos somar o número de homens e mulheres em cada grupo de idade. Para isso, nós somamos os valores da variável de peso amostral `V0010` em cada um desses grupos.

Repare que ao chamarmos a função `collect()`, o código é executado e retorna um `data.frame`.

```{r}
#| label: summarize-pop-table
piramide_df <- pop |>
               group_by(V0601, age_group) |>
               summarise(pop_count = sum(V0010)) |>
               collect()

head(piramide_df)
```
Pronto, o último passo é só fazer o gráfico de pirâmide populacional utilizando o pacote {ggplot2}.

```{r}
#| label: pop-pyramid-ggplot
#| code-fold: true
#| fig-cap: "Pirâmide demográfica, Brasil, 2010"

# remove grupo com idade missing `NA`
piramide_df <- filter(piramide_df, !is.na(age_group))

# transforma a contagem de mulheres para valores negativos
piramide_df <- piramide_df |>
  mutate(pop_count = if_else(V0601 == "Masculino", pop_count, -pop_count))

# figura
ggplot(data = piramide_df,
       aes(x = pop_count / 1000,
           y = age_group,
           fill = V0601)) +
  geom_col() +
  scale_fill_discrete(name="", type=c("#ffcb69","#437297")) +
  scale_x_continuous(labels = function(x){scales::comma(abs(x))},
                     breaks = c(-8000, -4000,0,4000, 8000),
                     name = "População (em milhares)") +
  theme_classic() +
  theme(
    legend.position = "top",
    axis.title.y=element_blank(),
    panel.grid.major.x = element_line(color = "grey90")
  )

```


# Dados de domicílios


### Using household data:

#### Sewage coverage:

In this example, we are going to map the proportion of households connected to a sewage network in Brazilian municipalities First, we can easily download the households data set with the `read_households()` function.

```{r}
hs <- read_households(year = 2010, 
                      showProgress = FALSE)

```

Now we're going to (a) group observations by municipality, (b) get the number of households connected to a sewage network, (c) calculate the proportion of households connected, and (d) collect the results.

```{r warning = FALSE}
esg <- hs |> 
        compute() |>
        group_by(code_muni) |>                                             # (a)
        summarize(rede = sum(V0010[which(V0207=='1')]),                    # (b)
                  total = sum(V0010)) |>                                   # (b)
        mutate(cobertura = rede / total) |>                                # (c)
        collect()                                                          # (d)

head(esg)
```


# Análise espacial com {geobr}

![](images/geobr_logo_y.png){width=150 fig-align="left"} ***Note:*** all data sets in **{censobr}** are enriched with geography columns following the name standards of the [{geobr} package](https://github.com/ipeaGIT/geobr/) to help data manipulation and integration with spatial data from {geobr}. The added columns are: `c(‘code_muni’, ‘code_state’, ‘abbrev_state’, ‘name_state’, ‘code_region’, ‘name_region’, ‘code_weighting’)`.




In order to create a map with these values, we are going to use the [{geobr} package](https://ipeagit.github.io/geobr/) to download the geometries of Brazilian municipalities.

```{r warning = FALSE}
library(geobr)

muni_sf <- geobr::read_municipality(year = 2010,
                                    showProgress = FALSE)
head(muni_sf)
```

Now we only need to merge the spatial data with our estimates and map the results.

```{r warning = FALSE}
esg_sf <- left_join(muni_sf, esg, by = 'code_muni')

ggplot() +
  geom_sf(data = esg_sf, aes(fill = cobertura), color=NA) +
  labs(title = "Share of households connected to a sewage network") +
  scale_fill_distiller(palette = "Greens", direction = 1, 
                       name='Share of\nhouseholds', 
                       labels = scales::percent) +
  theme_void()

```

#### Spatial distribution of rents:

In this final example, we're going to visualize how the amount of money people spend on rent varies spatially across the metropolitan area of São Paulo.

First, let's download the municipalities of the metro area of São Paulo.
```{r warning = FALSE}
metro_muni <- geobr::read_metro_area(year = 2010, 
                                     showProgress = FALSE) |> 
              subset(name_metro == "RM São Paulo")
```
We also need the polygons of the weighting areas (áreas de ponderação). With the code below, we download all weighting areas in the state of São Paulo, and then keep only the ones in the metropolitan region of São Paulo.

```{r warning = FALSE}
wt_areas <- geobr::read_weighting_area(code_weighting = "SP", 
                                       showProgress = FALSE,
                                       year = 2010)

wt_areas <- subset(wt_areas, code_muni %in% metro_muni$code_muni)
head(wt_areas)
```


Now we need to calculate the average rent spent in each weighting area. Using the national household data set, we're going to (a) filter only observations in our municipalities of interest, (b) group observations by weighting area, (c) calculate the average rent, and (d) collect the results.

```{r warning = FALSE}
rent <- hs |>
        filter(code_muni %in% metro_muni$code_muni) |>                     # (a)
        compute() |>
        group_by(code_weighting) |>                                        # (b)
        summarize(avgrent=weighted.mean(x=V2011, w=V0010, na.rm=TRUE)) |>  # (c)
        collect()                                                          # (d)

head(rent)
```
Finally, we can merge the spatial data with our rent estimates and map the results.

```{r warning = FALSE}
rent_sf <- left_join(wt_areas, rent, by = 'code_weighting')

ggplot() +
  geom_sf(data = rent_sf, aes(fill = avgrent), color=NA) +
  geom_sf(data = metro_muni, color='gray', fill=NA) +
  scale_fill_distiller(palette = "Greens", direction = 1, 
                       name='Avgerage\nRent in R$') +
  theme_void()

```



# Data cache

The first time the user runs a function, **{censobr}** will download the file and store it locally. This way, the data only needs to be downloaded once. When the `cache` parameter is set to `TRUE` (Default), the function will read the cached data, which is much faster. 

Users can manage the cached data sets using the `censobr_cache()` function. For example, users can:

List cached files:
```{r warning=FALSE}
censobr_cache(list_files = TRUE)
```

Delete a particular file:
```{r warning=FALSE}
censobr_cache(delete_file = "2010_emigration")

```

Delete all files:
```{r warning=FALSE}
censobr_cache(delete_file = "all")

```

By default, **{censobr}** files are saved in the 'User' directory. However, users can run the function `set_censobr_cache_dir()` to set custom cache directory.

```{r, eval=FALSE, warning=FALSE}
tempf <- tempdir()

set_censobr_cache_dir(path = tempf)

```

















