[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "1. Introdução à oficina",
    "section": "",
    "text": "Este site apresenta o material de apoio para a oficina “{censobr}: Explorando o Censo Demográfico em R”. A oficina será realizada como parte da programação do 23o Encontro da ABEP, em Brasília, entre os dias 23 e 26 de setembro de 2024.\n\n\n\n\n\n\n\nResumo da oficina:\nO Censo Demográfico é uma das mais importantes fontes de dados sobre as características e condições de vida da população brasileira. Nessa oficina, você vai aprender como baixar e manipular os dados das diversas edições do censo demográfico do Brasil de 1970 a 2022 usando o pacote {censobr} na linguagem de programação R.\nA oficina também vai demonstrar como o {censobr} permite trabalhar com grandes bases de dados (larger-than-memory data) e ser integrado com o pacote {geobr} para visualização espacial de dados em diferentes escalas geográficas.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAqui você encontra alguns slides explicando o que a gente cobre o que a gente não cobre com nesta oficina:\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEsta oficina assume que o participante tenha pelo menos um conhecimento básico da linguagem de programação R. Se você quiser se familiarizar com o R, recomendamos os livros abaixo:\n\nCiência de Dados em R\nR for Data Science\nGeocomputation with R\n\n\n\n\n\nSugestões de leitura:\nLeitura adicional relevante, mas não essencial para a oficina.\n\nO site e documentação do pacote {censobr}.\nO site e documentação do pacote {geobr}.\n\n\n\nSobre os instrutores:\nRafael H. M. Pereira  Coordenador de Ciência de Dados  Instituto de Pesquisa Econômica Aplicada (Ipea)  Website | Google Scholar | Twitter | Linkedin |\nRogério Barbosa  Professor de Sociologia  Instituto de Estudos Sociais e Políticos (IESP) da Universidade do Estado do Rio de Janeiro (UERJ)  Website | Google Scholar | Twitter | Linkedin |\n\nBio dos instrutors:\nRafael H. M. Pereira é pesquisador sênior nas áreas de planejamento urbano, ciência de dados espaciais e mobilidade urbana no Instituto de Pesquisa Econômica Aplicada (Ipea). Sua pesquisa investiga como as políticas urbanas e tecnologias moldam a organização espacial das cidades, a mobilidade humana, bem como seus impactos nas desigualdades sociais e de saúde. Algumas de suas contribuições nos campos de urban analytics e planejamento envolvem o desenvolvimento de novos métodos e ferramentas computacionais de código aberto para o estudo de sistemas urbanos e redes de transporte. Essas contribuições partem de interesses substantivos sobre questões de equidade no planejamento urbano, desigualdades de acesso a oportunidades, e dos impactos ambientais do ambiente construído e de padrões de mobilidade. Com graduação em sociologia pela UnB e mestrado em demografia pela Unicamp, Rafael Pereira obteve seu PhD em geografia pela Universidade de Oxford.\nRogério Barbosa é Professor de Sociologia do Instituto de Estudos Sociais e Políticos (IESP) da Universidade do Estado do Rio de Janeiro (UERJ), atuando nas áreas de Métodos Quantitativos e Estratificação Social. Formou-se bacharel em Ciências Sociais pela UFMG, mestre e doutor em Sociologia pela Universidade de São Paulo (2017). Realizou estágio pos-doutoral em Ciência Política pela USP e foi visiting scholar no Departamento de Sociologia da Columbia University. É pesquisador associado do Centro de Estudos da Metrópole (CEM-USP), affiliated scholar no Brazil Lad da Princeton University e membro da Rede de Pesquisa Solidária Políticas Públicas e Sociedade. Trabalhou como consultor metodológico de diversos grupos de pesquisa e também ministrou diversos cursos de programação e métodos estatísticos para instituições e universidades no Brasil. Atualmente pesquisa as tendências de longo prazo da desigualdade de renda no Brasil, usando levantamentos históricos e dados administrativos, bem como microdados contemporâneos. Desenvolve também pacotes R (código aberto) para pesquisa social e ferramentas para facilitar o acesso aos dados brasileiros para um público mais amplo.",
    "crumbs": [
      "1. Introdução à oficina"
    ]
  },
  {
    "objectID": "3.2_flexible_approach.html",
    "href": "3.2_flexible_approach.html",
    "title": "Flexible approach",
    "section": "",
    "text": "test\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis flexible approach to calculate accessibility only involves 3 steps:\n\nBuilding a routable transport network\nComputing a travel time matrix\nCalculating accessibility\n\nNow let’s start loading the packages we need:\n\n library(dplyr)\n library(ggplot2)\n\n\n\n\n\n\n\ntest test",
    "crumbs": [
      "3. Calculating accessibility",
      "Flexible approach"
    ]
  },
  {
    "objectID": "3.2_flexible_approach.html#cumulative-accessibility-measure",
    "href": "3.2_flexible_approach.html#cumulative-accessibility-measure",
    "title": "Flexible approach",
    "section": "3.1 Cumulative accessibility measure",
    "text": "3.1 Cumulative accessibility measure\n\nThreshold-based cumulative accessibility\nTo calculate a traditional cumulative accessibility measure, we can use the accessibility::cumulative_cutoff() function. Along with the travel matrix and land use data sets, we only need to pass the name of the column with the travel time values, the name of the column with the count of opportunities, and a travel time cutoff.\nHere, we calculate the number of schools accessible in 20 minutes.\n\n# threshold-based cumulative accessibility\naccess_cum_t &lt;- accessibility::cumulative_cutoff(\n  travel_matrix = ttm, \n  land_use_data = points,\n  travel_cost = 'travel_time_p50',\n  opportunity = 'schools',\n  cutoff = 20\n  )\n  \nhead(access_cum_t)\n\n                id schools\n            &lt;char&gt;   &lt;int&gt;\n1: 89a9012124fffff       1\n2: 89a9012126bffff       3\n3: 89a9012127bffff       3\n4: 89a90128003ffff       8\n5: 89a90128007ffff       6\n6: 89a9012800bffff       9\n\n\n\n\nInterval-based cumulative accessibility\nPrevious studies have shown that the ad-hoc choice of a single travel time threshold can substantially influence the results of traditional cumulative accessibility measures, introducing bias into transport project evaluations and equity analyses (Pereira 2019). To overcome this issue, we have proposed a time interval cumulative accessibility measure (Tomasiello et al. 2023). This new metric estimates the average (or the median) number of opportunities that can be reached considering multiple minute-by-minute cutoffs within a given travel time interval.\nThe main advantage of this metric is that it mitigates the impacts of arbitrary choices of trip duration on accessibility analysis while preserving the computation and communicability advantages of threshold-based cumulative measures.\nHere, we calculate the average number of schools that can be reached between 20 and 30 minutes.\n\n# interval-based cumulative accessibility\naccess_cum_i &lt;- accessibility::cumulative_interval(\n  travel_matrix = ttm, \n  land_use_data = points,\n  travel_cost = 'travel_time_p50',\n  opportunity = 'schools',\n  interval = c(15,25),\n  summary_function = mean\n  )\n  \nhead(access_cum_i)\n\n                id schools\n            &lt;char&gt;   &lt;int&gt;\n1: 89a9012124fffff       1\n2: 89a9012126bffff       4\n3: 89a9012127bffff       4\n4: 89a90128003ffff       7\n5: 89a90128007ffff       7\n6: 89a9012800bffff       9",
    "crumbs": [
      "3. Calculating accessibility",
      "Flexible approach"
    ]
  },
  {
    "objectID": "3.2_flexible_approach.html#gravity-based-accessibility-measures",
    "href": "3.2_flexible_approach.html#gravity-based-accessibility-measures",
    "title": "Flexible approach",
    "section": "3.2 Gravity-based accessibility measures",
    "text": "3.2 Gravity-based accessibility measures\nThe package also includes accessibility::gravity() to calculate gravity-based accessibility metrics in a very flexible way.\nIt includes a decay_function parameter that can receive any function to convert travel cost into an impedance factor used to weight opportunities. For convenience, the package currently includes the following functions:\n\ndecay_binary()\ndecay_exponential()\ndecay_linear()\ndecay_logistic()\ndecay_power()\ndecay_stepped()\n\nLet’s see a couple examples with logistic and negative exponential decay functions:\n\n# logistic decay\naccess_lgst &lt;- gravity(\n  travel_matrix = ttm,\n  land_use_data = points,\n  decay_function = decay_logistic(cutoff = 15, sd = 5),\n  opportunity = \"schools\",\n  travel_cost = \"travel_time_p50\"\n)\n\n# negative exponential decay\naccess_nexp &lt;- gravity(\n  travel_matrix = ttm,\n  land_use_data = points,\n  decay_function = decay_exponential(decay_value = 0.1),\n  opportunity = \"schools\",\n  travel_cost = \"travel_time_p50\"\n)\n\nHere’s a quick visualization of the shape of the decay curves we’ve used.\n\n\nCode\nnegative_exp &lt;- decay_exponential(decay_value = 0.1)\nlogistic &lt;- decay_logistic(cutoff = 15, sd = 5)\n\ntravel_costs &lt;- seq(0, 30, 0.1)\n\nweights &lt;- data.frame(\n  minutes = travel_costs,\n  negative_exp = negative_exp(travel_costs)[[\"0.1\"]],\n  logistic = logistic(travel_costs)[[\"c15;sd5\"]]\n)\n\n# reshape data to long format\nweights &lt;- tidyr::pivot_longer(\n  weights,\n  cols = c('negative_exp',  'logistic'),\n  names_to = \"decay_function\",\n  values_to = \"weights\"\n)\n\nggplot(weights) +\n  geom_line(aes(minutes, weights, color = decay_function),\n            show.legend = FALSE) +\n  facet_wrap(. ~ decay_function, ncol = 2) +\n  theme_minimal()",
    "crumbs": [
      "3. Calculating accessibility",
      "Flexible approach"
    ]
  },
  {
    "objectID": "2.2_data_requirements.html",
    "href": "2.2_data_requirements.html",
    "title": "Data requirements",
    "section": "",
    "text": "In order to conduct transport routing and accessibility analysis using the {r5r} package, you will need a few input data sets:\n\nA road network from OpenStreetMap (OSM) in .pbf format (mandatory).\nA public transport feed inGTFS.zip format (optional).\nA raster file with Digital Elevation Model data in .tif format (optional).\nSome data on the spatial distribution of population and/or activities such as employment, schools, health care facilities.\n\nThe data sets we’ll use in this workshop are provided with the code exercises. If you would like to find similar data for you other regions in the world, here are a few data sources. See also slides below.\n\nStreet network (mandatory):\n\n{osmextract}, R package;\nGeofabrik, website;\nHOT Export Tool, website;\nBBBike Extract Service, website.\nProtomaps website\n\nPublic transport network (optional):\n\n{tidytransit}, R package;\nTransitland, website;\nMobility Database website\n\nTopography (optional):\n\n{elevatr}, R package;\nNasa’s SRTMGL1, website.",
    "crumbs": [
      "2. Getting started",
      "Data requirements"
    ]
  },
  {
    "objectID": "2.1_installation.html",
    "href": "2.1_installation.html",
    "title": "Installation",
    "section": "",
    "text": "To follow the workshop, you should have the following programs installed on your machine before the day of the workshop.\n\nR and RStudio\nA few R packages\nJava JDK 21\n\nSee instructions below:\n\n\n\n\nInstalling R and RStudio\nWe assume you already have R and RStudio installed on your machine. In case you don’t, follow these simple instructions here.\n\n\nInstalling R packages\nThe workshop uses a few R packages that need to be installed on your machine. The simplest way to do this is running the code below. This might take a few minutes if this is the first time you install these packages.\n\npkgs &lt;- c(\n  'r5r',\n  'accessibility',\n  'rJavaEnv',\n  'ggplot2',\n  'mapview',\n  'dplyr',\n  'h3jsr',\n  'sf'\n  )\n\ninstall.packages(pkgs)\n\nThe safest way to replicate the code of this workshop, though, is cloning its repository locally. This is because this repository uses the {renv} R package to manage the package dependencies of the code we use. This is important to make sure we are using the same versions of the relevant packages.\nOnce you have cloned the repo and you’ve opened the access_workshop_eit_2024.Rproj file, you can simply run renv::restore() to install all the package dependencies used in this workshop.\n\n# uncomment the line below in case you need to install the {renv} package\n# install.packages('renv')\nrenv::restore()\n\n\n\nInstalling Java\nTo use the {r5r} package (version v2.0 or higher), you will need to have Java Development Kit (JDK) 21 installed on your computer. There are numerous open-source JDK implementations. The easiest way to install JDK is using the new {rJavaEnv} package in R, developed by Egor Kotov (thanks Egor!).\n\n# check version of Java currently installed (if any) \nrJavaEnv::java_check_version_rjava()\n\n## if this is the first time you use {rJavaEnv}, you might need to run this code\n## below to consent the installation of Java.\n# rJavaEnv::rje_consent(provided = TRUE)\n\n# install Java 21\nrJavaEnv::java_quick_install(\n  version = 21,\n  distribution = 'Corretto')\n\n# check if Java was successfully installed\nrJavaEnv::java_check_version_rjava()\n\nAlternatively, you can manually download and install any of these JDK implementations:\n\nAdoptium/Eclipse Temurin\nAmazon Corretto\nOracle OpenJDK\n\nHere are a few accompanying slides explaining the computational requirements to conduct transport routing and accessibility analysis with R.",
    "crumbs": [
      "2. Getting started",
      "Installation"
    ]
  },
  {
    "objectID": "3.1_quick_approach.html",
    "href": "3.1_quick_approach.html",
    "title": "Quick approach",
    "section": "",
    "text": "In this first hands-on section of the workshop, we’ll learn a very quick and simple way to calculate spatial accessibility using the {r5r} package. In the next section, we’ll see a more flexible and robust way to do the same thing. Here we’ll be calculating the number of schools accessible by public transport within a travel time of 20 minutes.\n\n1. Allocating memory to Java & loading packages\nFirst, let’s increase the memory available to run Java, which is used by the underlying R5 routing engine. To increase the available memory to 2 GB, for example, we use the following command. Note that this needs to be run before loading the packages that will be used in our analysis.\n\n library(dplyr)\n library(ggplot2)",
    "crumbs": [
      "3. Calculating accessibility",
      "Quick approach"
    ]
  },
  {
    "objectID": "3.3_equity_measures.html",
    "href": "3.3_equity_measures.html",
    "title": "Equity measures",
    "section": "",
    "text": "A central question in transportation research and practice involves assessing how the accessibility benefits of transportation systems and projects are distributed across different socioeconomic and demographic groups. Transportation equity concerns are fundamentally related to two types of issues: (1) accessibility inequality and (2) accessibility poverty. In this section you will learn how to use the {accessibility} package to calculate different indicators of accessibility inequality and poverty. \nIn a recent paper, we discussed the advantages and disadvantages of various inequality and poverty metrics most commonly used in the transport literature (Karner, Pereira, and Farber 2024) - ungated PDF here. The slides below give a very short summary of some ideas discussed in the paper. Just enough to follow this workshop section. Nonetheless, I would strongly recommend reading the whole paper.\n\n\n\n\nIn this section, we’ll be using a couple sample data sets for the city of Belo Horizonte (Brazil), which come with the {accessibility} package. In the code chunk below, we read the travel time matrix and land use data, and calculate the average number of jobs accessible in 30 by public transport.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# path to data\n22 \n\n[1] 22\n\n\n\n\n\nReferences\n\nKarner, Alex, Rafael H. M. Pereira, and Steven Farber. 2024. “Advances and Pitfalls in Measuring Transportation Equity.” Transportation, January. https://doi.org/10.1007/s11116-023-10460-7.",
    "crumbs": [
      "3. Calculating accessibility",
      "Equity measures"
    ]
  },
  {
    "objectID": "3.3_equity_measures.html#palma-ratio",
    "href": "3.3_equity_measures.html#palma-ratio",
    "title": "Equity measures",
    "section": "Palma ratio",
    "text": "Palma ratio\nThe Palma ratio is calculated as the average access of the richest 10% divided by the average access of the poorest 40%. Palma Ratio values higher than 1 indicate that the wealthiest population has higher accessibility levels than the poorest, whereas values lower than 1 indicate the opposite situation.\nIn the example here, we see that the wealthiest population can access on average 3.8 times more jobs than the poor population.\n\npalma &lt;- palma_ratio(\n  accessibility_data = access_df,\n  sociodemographic_data = lud,\n  opportunity = \"jobs\",\n  population = \"population\",\n  income = \"income_per_capita\"\n  )\n\npalma\n\n   palma_ratio\n         &lt;num&gt;\n1:    3.800465",
    "crumbs": [
      "3. Calculating accessibility",
      "Equity measures"
    ]
  },
  {
    "objectID": "3.3_equity_measures.html#concentration-index",
    "href": "3.3_equity_measures.html#concentration-index",
    "title": "Equity measures",
    "section": "Concentration index",
    "text": "Concentration index\nThe concentration index (CI) estimates the extent to which accessibility inequalities are systematically associated with individuals’ socioeconomic levels. CI values can theoretically vary between -1 and 1 (when all accessibility is concentrated in the most or in the least disadvantaged person, respectively). Negative values indicate that inequalities favor the poor, while positive values indicate a pro-rich bias.\n\nci &lt;- accessibility::concentration_index(\n  accessibility_data = access_df,\n  sociodemographic_data = lud,\n  opportunity = \"jobs\",\n  population = \"population\",\n  income = \"income_per_capita\",\n  type = \"corrected\"\n  )\n\nci\n\n   concentration_index\n                 &lt;num&gt;\n1:           0.3346494",
    "crumbs": [
      "3. Calculating accessibility",
      "Equity measures"
    ]
  },
  {
    "objectID": "3.3_equity_measures.html#gini-index",
    "href": "3.3_equity_measures.html#gini-index",
    "title": "Equity measures",
    "section": "Gini index",
    "text": "Gini index\nYou probably shouldn’t use the Gini index to measure accessibility inequality (see Karner, Pereira, and Farber 2024).",
    "crumbs": [
      "3. Calculating accessibility",
      "Equity measures"
    ]
  },
  {
    "objectID": "3.3_equity_measures.html#foster-greer-thorbecke-fgt-poverty-measures",
    "href": "3.3_equity_measures.html#foster-greer-thorbecke-fgt-poverty-measures",
    "title": "Equity measures",
    "section": "Foster-Greer-Thorbecke (FGT) poverty measures",
    "text": "Foster-Greer-Thorbecke (FGT) poverty measures\nThe fgt_poverty() function calculates the FGT metrics, a family of poverty measures originally proposed by Foster, Greer, and Thorbecke (1984), and which that can be used to capture the extent and severity of poverty within an accessibility distribution. The FGT family is composed of three measures:\n\nFGT0: it captures the extent of poverty as a simple headcount - i.e. the proportion of people below the poverty line;\nFGT1: also know as the “poverty gap index”, it captures the severity of poverty as the average percentage distance between the poverty line and the accessibility of individuals below the poverty line;\nFGT2: it simultaneously captures the extent and the severity of poverty by calculating the number of people below the poverty line weighted by the size of the accessibility shortfall relative to the poverty line.\n\nThis function includes an additional poverty_line parameter, used to define the poverty line below which individuals are considered to be in accessibility poverty. For the sake of this exercise, we’ll consider the lowest 25th percentile of access as our poverty line, which in this example is approximately 23 thousand jobs.\n\n\n\n\n\n\nQuick reminder that the definition of an accessibility poverty line is ultimately a moral and political decision and not simply an empirical or technical question (Pereira, Schwanen, and Banister 2017; Lucas et al. 2019).\n\n\n\n\n# get the 25th percentile of access\nquant25 &lt;- quantile(access_df$jobs, .25)\n\npoverty &lt;- fgt_poverty(\n  accessibility_data =  access_df,\n  sociodemographic_data = lud,\n  opportunity = \"jobs\",\n  population = \"population\",\n  poverty_line = quant25\n  )\n\npoverty\n\n        FGT0       FGT1       FGT2\n       &lt;num&gt;      &lt;num&gt;      &lt;num&gt;\n1: 0.1478675 0.04948043 0.02862334\n\n\nQuick interpretation:\n\nFGT0: 14.8% of the population are in accessibility poverty\nFGT1: the accessibility of those living in accessibility poverty is on average 5% lower than the poverty line\nFGT2: it has no clear interpretation, but one could say that the overall poverty level/intensity is 2.8%.",
    "crumbs": [
      "3. Calculating accessibility",
      "Equity measures"
    ]
  },
  {
    "objectID": "2.1_installation.knit.html",
    "href": "2.1_installation.knit.html",
    "title": "Installation",
    "section": "",
    "text": "To follow the workshop, you should have the following programs installed on your machine before the day of the workshop.\n\nR and RStudio\nA few R packages\nJava JDK 21\n\nSee instructions below:\n\n\n\n\nInstalling R and RStudio\nWe assume you already have R and RStudio installed on your machine. In case you don’t, follow these simple instructions here.\n\n\nInstalling R packages\nThe workshop uses a few R packages that need to be installed on your machine. The simplest way to do this is running the code below. This might take a few minutes if this is the first time you install these packages.\n\npkgs &lt;- c(\n  'r5r',\n  'accessibility',\n  'rJavaEnv',\n  'ggplot2',\n  'mapview',\n  'dplyr',\n  'h3jsr',\n  'sf'\n  )\n\ninstall.packages(pkgs)\n\nThe safest way to replicate the code of this workshop, though, is cloning its repository locally. This is because this repository uses the {renv} R package to manage the package dependencies of the code we use. This is important to make sure we are using the same versions of the relevant packages.\nOnce you have cloned the repo and you’ve opened the access_workshop_eit_2024.Rproj file, you can simply run renv::restore() to install all the package dependencies used in this workshop.\n\n# uncomment the line below in case you need to install the {renv} package\n# install.packages('renv')\nrenv::restore()\n\n\n\nInstalling Java\nTo use the {r5r} package (version v2.0 or higher), you will need to have Java Development Kit (JDK) 21 installed on your computer. There are numerous open-source JDK implementations. The easiest way to install JDK is using the new {rJavaEnv} package in R, developed by Egor Kotov (thanks Egor!).\n\n# check version of Java currently installed (if any) \nrJavaEnv::java_check_version_rjava()\n\n## if this is the first time you use {rJavaEnv}, you might need to run this code\n## below to consent the installation of Java.\n# rJavaEnv::rje_consent(provided = TRUE)\n\n# install Java 21\nrJavaEnv::java_quick_install(\n  version = 21,\n  distribution = 'Corretto')\n\n# check if Java was successfully installed\nrJavaEnv::java_check_version_rjava()\n\nAlternatively, you can manually download and install any of these JDK implementations:\n\nAdoptium/Eclipse Temurin\nAmazon Corretto\nOracle OpenJDK\n\nHere are a few accompanying slides explaining the computational requirements to conduct transport routing and accessibility analysis with R."
  },
  {
    "objectID": "2.1_instalacao.knit.html",
    "href": "2.1_instalacao.knit.html",
    "title": "Installation",
    "section": "",
    "text": "To follow the workshop, you should have the following programs installed on your machine before the day of the workshop.\n\nR and RStudio\nA few R packages\nJava JDK 21\n\nSee instructions below:\n\n\n\n\nInstalling R and RStudio\nWe assume you already have R and RStudio installed on your machine. In case you don’t, follow these simple instructions here.\n\n\nInstalling R packages\nThe workshop uses a few R packages that need to be installed on your machine. The simplest way to do this is running the code below. This might take a few minutes if this is the first time you install these packages.\n\npkgs &lt;- c(\n  'r5r',\n  'accessibility',\n  'rJavaEnv',\n  'ggplot2',\n  'mapview',\n  'dplyr',\n  'h3jsr',\n  'sf'\n  )\n\ninstall.packages(pkgs)\n\nThe safest way to replicate the code of this workshop, though, is cloning its repository locally. This is because this repository uses the {renv} R package to manage the package dependencies of the code we use. This is important to make sure we are using the same versions of the relevant packages.\nOnce you have cloned the repo and you’ve opened the access_workshop_eit_2024.Rproj file, you can simply run renv::restore() to install all the package dependencies used in this workshop.\n\n# uncomment the line below in case you need to install the {renv} package\n# install.packages('renv')\nrenv::restore()\n\n\n\nInstalling Java\nTo use the {r5r} package (version v2.0 or higher), you will need to have Java Development Kit (JDK) 21 installed on your computer. There are numerous open-source JDK implementations. The easiest way to install JDK is using the new {rJavaEnv} package in R, developed by Egor Kotov (thanks Egor!).\n\n# check version of Java currently installed (if any) \nrJavaEnv::java_check_version_rjava()\n\n## if this is the first time you use {rJavaEnv}, you might need to run this code\n## below to consent the installation of Java.\n# rJavaEnv::rje_consent(provided = TRUE)\n\n# install Java 21\nrJavaEnv::java_quick_install(\n  version = 21,\n  distribution = 'Corretto')\n\n# check if Java was successfully installed\nrJavaEnv::java_check_version_rjava()\n\nAlternatively, you can manually download and install any of these JDK implementations:\n\nAdoptium/Eclipse Temurin\nAmazon Corretto\nOracle OpenJDK\n\nHere are a few accompanying slides explaining the computational requirements to conduct transport routing and accessibility analysis with R."
  },
  {
    "objectID": "2.1_instalacao.html",
    "href": "2.1_instalacao.html",
    "title": "2.1 Instalação",
    "section": "",
    "text": "Para acompanhar a oficina, você deve ter os seguintes programas instalados em sua máquina antes do dia do workshop\n\nR e RStudio\nAlguns pacotes de R\n\nInstruções abaixo:\n\n\n\n\nInstalando R e RStudio\nNesta oficina, a gente pressupõe que você já tenha o R e o RStudio instalados em sua máquina. Caso ainda precise instalar esses programas, siga estras instruções.\n\n\nInstalando pacotes de R\nA oficina utiliza alguns pacotes do R que precisam ser instalados em sua máquina. A maneira mais simples de fazer isso é executando o código abaixo. Isso pode levar alguns minutos, caso seja a primeira vez que você instala esses pacotes.\n\npkgs &lt;- c(\n  'censobr',\n  'geobr',\n  'arrow',\n  'dplyr',\n  'ggplot2'\n  )\n\ninstall.packages(pkgs)\n\nA maneira mais segura de replicar o código desta oficina, no entanto, é clonando o seu repositório localmente. Isso porque este repositório utiliza o pacote {renv}do R para gerenciar as dependências dos pacotes utilizados na oficina. Isso é importante para garantir que estamos utilizando as mesmas versões dos pacotes relevantes.\nUma vez que você clonou o repositório e abriu o arquivo censobr_oficina_abep_2024.Rproj, basta você rodar renv::restore() para instalar todos os pacotes utilizados nesta oficina.\n\n# Descomente a linha abaixo caso precise instalar o pacote {renv}\n# install.packages('renv')\nrenv::restore()",
    "crumbs": [
      "2. Informações gerais",
      "2.1 Instalação"
    ]
  },
  {
    "objectID": "2.2_info_censo.html",
    "href": "2.2_info_censo.html",
    "title": "2.2 Conceitos iniciais",
    "section": "",
    "text": "O censo demográfico brasileiro é a principal pesquisa populacional realizada no Brasil, conduzida pelo Instituto Brasileiro de Geografia e Estatística (IBGE). Trata-se da pesquisa de maior cobertura territorial do país, e que levanta informações sobre as características e condições de vida da população brasileira nos mais diversos temas, como perfil demográfico, educação, trabalho, fecundidade, migração, condições de moradia, etc.\nNesta seção, nós revisamos alguns conceitos básicos sobre a organização dos censo demográficos no Brasil.",
    "crumbs": [
      "2. Informações gerais",
      "2.2 Conceitos iniciais"
    ]
  },
  {
    "objectID": "2.2_info_censo.html#setores-censitários",
    "href": "2.2_info_censo.html#setores-censitários",
    "title": "2.2 Conceitos iniciais",
    "section": "Setores censitários",
    "text": "Setores censitários\n\nOs cetores censitários são a menor unidade de análise espacial nas pesquisas domiciliares do IBGE. Um setor é uma unidade territorial demarcada para fins operacionais de organizar a coleta de dados. Cada setor é coberto por um único recenseador e possui em média, cerca de 200 domicílios. No entanto, este número, assim como a o tamanho do setor podem variar a depender da densidade demográfica de cada região. Os dados do universo são disponibilizados apenas no formato agregado por setores censitários.\n\n\nÁreas de ponderação\n\nAs áreas de ponderação são a menor unidade espacial para a qual os dados da pesquisa amostral possuem representatividade estatística. Essas áras são constituídas por agrupamentos de setores censitários contíguos, mas que também variam de acordo com a densidade demográfica de cada região. Para o Censo de 2010, o IBGE estabeleceu que uma área de ponderação deveria ter, no mínimo, 400 domicílios ocupados na amostra. Em regiões menos densamente povoadas, essas áreas acabam ocupando uma larga extensão territorial.\n\n\n\nCode\nlibrary(geobr)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(sf)\n\n# codigo do municipio de Belford Roxo\nmymuni &lt;- 3300456\n\n# baixa geometria do municipio\nmuni &lt;- geobr::read_municipality(mymuni)\n\n# baixa geometria das areas de ponderacao\nap &lt;- geobr::read_weighting_area(code_weighting = mymuni, \n                                 year = 2010, \n                                 simplified = F)\n\n# baixa geometria dos setores censitarios\nct &lt;- geobr::read_census_tract(code_tract = mymuni, \n                               year = 2010, \n                               simplified = FALSE)\n\n# funcao para 'inclinar' mapa\nrotate_data_geom &lt;- function(data, x_add = 0, y_add = 0) {\n  shear_matrix &lt;- function(){ matrix(c(2, 1.2, 0, 1), 2, 2) }\n  \n  rotate_matrix &lt;- function(x) { \n    matrix(c(cos(x), sin(x), -sin(x), cos(x)), 2, 2) \n  }\n  dplyr::mutate(data,\n    geom = geom * shear_matrix() * rotate_matrix(pi/20) + c(x_add, y_add)\n    )\n}\n\n\n# annotate parameters\nx = -116.03\nclr = 'gray40'\nsz = 4\n\n# MAP\ntemp1  &lt;- ggplot() +\n  # municipio\n  geom_sf(data = rotate_data_geom(data = muni, y_add = .01),\n          color='gray30', fill='#FCDE70', show.legend = FALSE) +\n  annotate(\"text\", label='Município', x=x, y=-4.59,\n           hjust = 0, color=clr, size=sz) +\n  \n  # areas de ponderacao\n  geom_sf(data = rotate_data_geom(data = ap, y_add = .07), \n          fill='#ff7b7b', color='#ff0000', show.legend = FALSE) +\n  annotate(\"text\", label='Áreas de\\nPonderação', x=x, y= -4.53,\n           hjust = 0, color=clr, size=sz) +\n\n  # setores censitarios\n  geom_sf(data = rotate_data_geom(data = ct, y_add = 0.13),\n          color='gray30', fill='gray98', show.legend = FALSE) +\n  annotate(\"text\", label='Setores\\nCensitários', x=x, y= -4.47, \n           hjust = 0, color=clr, size=sz) +\n  coord_sf(xlim = c(-116.305, -115.98)) +\n  theme_void() +\n  theme(plot.background = element_rect(fill = 'white', color='white'))\n\ntemp1\n# ggsave(temp1, filename = 'fig_spatial_layers.png', \n#        width = 12, height = 8, units = 'cm', dpi = 300)",
    "crumbs": [
      "2. Informações gerais",
      "2.2 Conceitos iniciais"
    ]
  },
  {
    "objectID": "5_agregados_setores.html",
    "href": "5_agregados_setores.html",
    "title": "5. Agregados dos Setores Censitários",
    "section": "",
    "text": "t\n1+3\n\n[1] 4\nPerhaps the most commonly used datasets from Brazilian censuses are the microdata of individuals and households. Nonetheless, IBGE also makes available some extremely data on population and environmental characteristics aggregated at the census tract level. In this vignette, we show how to use the censobr package to easily access census tract-level data using the read_tracts() function.\nAt the moment, this function only includes data from the 2010 census.",
    "crumbs": [
      "5. Agregados dos Setores Censitários"
    ]
  },
  {
    "objectID": "3_microdados.html",
    "href": "3_microdados.html",
    "title": "3. Microdados",
    "section": "",
    "text": "under construction\nTabela 1. Funções de dados disponíveis no {censobr}\n  \n    \n    \n\n\n\nFunção\nOrigem\nUnidade\nDefinição\nDisponibilidade\n\n\n\n1960\n1970\n1980\n1991\n2000\n2010\n2022\n\n\n\n\nread_population()\nAmostra\nMicrodado\nLê os microdados de pessoas.\n\nX\nX\nX\n\nX\n\n\n\nread_households()\nAmostra\nMicrodado\nLê os microdados de domicílios.\n\nX\nX\nX\n\nX\n\n\n\nread_families()\nAmostra\nMicrodado\nLê os microdados de famílias do censo de 2000.\n\n\n\nX\n\n\n\n\n\nread_emigration()\nAmostra\nMicrodado\nLê os microdados de emigração do censo de 2010. Cada unidade é uma pessoa que se mudou para outro país nos 12 meses anteriores ao censo, com informações fornecidas pelos outros moradores do domicílio.\n\n\n\n\nX\n\n\n\n\nread_mortality()\nAmostra\nMicrodado\nLê os microdados de mortalidade do censo de 2010. Cada unidade é uma pessoa falecida nos 12 meses anteriores ao censo, com informações fornecidas pelos outros moradores do domicílio.\n\n\n\nX\n\n\n\n\n\nread_tracts()\nUniverso\nSetor Censitário\nLê os dados do Universo agregados por setores censitários.\n\nX\nX\nX\n\nX",
    "crumbs": [
      "3. Microdados"
    ]
  },
  {
    "objectID": "4_documentacao.html",
    "href": "4_documentacao.html",
    "title": "4. Documentação",
    "section": "",
    "text": "Além de funções para leitura dos dados, o pacote {censobr} traz ainda um conjunto de funções que permitem rápido acesso à documentação dos censos demográficos, incluindo os dicionários de variáveis, questionários e manual do entrevistador para envistas.\nTabela 2. Funções de documentação disponíveis no {censobr}\n    \n    \n    \n\n\n\nFunção\nDocumentação\nTipo\nDisponibilidade\n\n\n1960\n70\n80\n91\n2000\n10\n22\n\n\n\n\ndata_dictionary()\nDicionário de variáveis\nMicrodados\nX\nX\nX\n\nX\n\nX\n\n\nAgregados de setores censitários\n\n\n\n\nX\n\nX\n\n\nquestionnaire()\nQuestionários\nLongo e curto\nX\nX\nX\nX\nX\nX\nX\n\n\ninterview_manual()\nManual do entrevistador\n-\n\nX\nX\nX\nX\n\nX\n\n\n\nTodas funções de documentação baixam os arquivos em formato .html ou .pdf, e abrem o documento no navegador (browser). Assim como as funções de leitura de dados do {censobr}, essas funções de documentação também salval os arquivos num cache local na primeira vez que a função é rodada. Assim, quando o usuário roda a função novamente, o pacote simplesmente carrega o arquivo local de maneira quase instantânea.\n\nDicionário de dados\nThe data_dictionary() indicate the definition of each variable, and the meaning of their categories in the case of categorical variables. The function currently covers the data dictionaries for all Brazilian censuses since 1970 (1970, 1980, 1991, 2000 and 2010), and it includes dictionaries for the variables of both microdata (sample portion of the census) and for the variables available in census tract-level aggregate data.\nA função data_dictionary() carrega o dicionário de variáveis, apontando a definição de cada variável e o significado de suas categorias no caso de variáveis categóricas. Atualmente, a função abrange os dicionários dos microdados da amostra para todos os censos brasileiros desde 1970 c(1970, 1980, 1991, 2000 e 2010). Além disso, a função também inclui os dicionários dos dados do universo agregados em setores censitário para os anos 2000 e 2010.\n\nlibrary(censobr)\n\n# dicionário de variáveis de pessoas (microdados da amostra)\ndata_dictionary(year = 2010, \n                dataset = 'population')\n\n# dicionário de variáveis de domicílios (microdados da amostra)\ndata_dictionary(year = 2010, \n                dataset = 'households')\n\n\n# dicionário de variáveis de setores censitários (agregados do universo)\ndata_dictionary(year = 2010, \n                dataset = 'tracts')\n\n\n\nQuestionários\nCom frequência, é importante se entender a estrutura e fluxo do questionário utilizado em pesquisas de coleta de dados. A função questionnaire() inclui os questionários utilizados na coleta de dados de todos os censos brasileiros desde 1960.\nAlém de passar o parâmetro year, o usuário precisa indicar o tipo de questionário de interesse, se o questionário curto do universo (type = 'short') ou o questionário longo utilizado na pesquisa amostra (type = 'long').\n\n# questionário curto da pesquisa do universo\nquestionnaire(year = 2010, \n              type = 'short')\n\n# questionário longo da pesquisa amostral\nquestionnaire(year = 2010, \n              type = 'long')\n\n\n\nManual do entrevistador\nPor fim, a função interview_manual() faz o download e abre no navegador o “Manual do Recenseador”, ou seja, o manual de instruções para os recenseadores do IBGE sobre como coletar os dados do censo. Estão disponíveis os manuais de todos os censos desde 1970.\n\n# Censo de 2010\ninterview_manual(year = 2010)\n\n# Censo de 1970\ninterview_manual(year = 1970)",
    "crumbs": [
      "4. Documentação"
    ]
  },
  {
    "objectID": "5_agregados_setores.knit.html",
    "href": "5_agregados_setores.knit.html",
    "title": "5. Agregados dos Setores Censitários",
    "section": "",
    "text": "t\n\n1+3\n\n[1] 4\n\n\nTabela 2. Funções de documentação disponíveis no {censobr}\n    \n    \n    \n\n\n\nFunção\nDocumentação\nTipo\nDisponibilidade\n\n\n1960\n70\n80\n91\n2000\n10\n22\n\n\n\n\ndata_dictionary()\nDicionário de variáveis\nMicrodados\nX\nX\nX\n\nX\n\nX\n\n\nAgregados de setores censitários\n\n\n\n\nX\n\nX\n\n\nquestionnaire()\nQuestionários\nLongo e curto\nX\nX\nX\nX\nX\nX\nX\n\n\ninterview_manual()\nManual do entrevistador\n-\n\nX\nX\nX\nX\n\nX"
  },
  {
    "objectID": "5_agregados_setores.html#dictionary-of-variables",
    "href": "5_agregados_setores.html#dictionary-of-variables",
    "title": "5. Agregados dos Setores Censitários",
    "section": "Dictionary of variables",
    "text": "Dictionary of variables\nTo check the meaning of each variable, users can run the data_dictionary(), which will open on the browser an .html or .pdf file with the dictionary of variables in each dataset\n\ndata_dictionary(year = 2010, dataset = 'tracts')",
    "crumbs": [
      "5. Agregados dos Setores Censitários"
    ]
  },
  {
    "objectID": "5_agregados_setores.html#example-1-spatial-distribution-of-income",
    "href": "5_agregados_setores.html#example-1-spatial-distribution-of-income",
    "title": "5. Agregados dos Setores Censitários",
    "section": "Example 1: Spatial distribution of income",
    "text": "Example 1: Spatial distribution of income\nIn this first example we’ll be creating a map of the spatial distribution of average income per capita. We can find the information on the the total number of residents in each census tract in the \"Basico\" dataset, variable \"V002\". Meanwhile, the information on income can be found in the \"DomicilioRenda\" dataset, variable \"V003\".\nUsing the code below, we download the data and calculate the income per capita of all census tracts in Brazil.\n\n# download data\ntract_basico &lt;- read_tracts(year = 2010,\n                            dataset = \"Basico\", \n                            showProgress = FALSE)\n\nDownloading data and storing it locally for future use.\n\ntract_income &lt;- read_tracts(year = 2010,\n                            dataset = \"DomicilioRenda\", \n                            showProgress = FALSE)\n\nDownloading data and storing it locally for future use.\n\n# select columns\ntract_basico &lt;- tract_basico |&gt; select('code_tract','V002')\ntract_income &lt;- tract_income |&gt; select('code_tract','V003')\n\n# merge\ntracts_df &lt;- left_join(tract_basico, tract_income) |&gt; collect()\n\n# calculate income per capita\ntracts_df &lt;- tracts_df |&gt; mutate(income_pc = V003 / V002)\nhead(tracts_df)\n\n        code_tract  V002   V003 income_pc\n            &lt;char&gt; &lt;num&gt;  &lt;num&gt;     &lt;num&gt;\n1: 120001305000001   957 601805  628.8454\n2: 120001305000002  1203 385033  320.0607\n3: 120001305000003  1700 531794  312.8200\n4: 120001305000004   182  58853  323.3681\n5: 120001305000005   305 112979  370.4230\n6: 120001305000006   483 263538  545.6273\n\n\nFinally, we can merge the spatial data with our per capita income estimates and map the results.\n\nbh_tracts &lt;- left_join(tracts_sf, tracts_df, by = 'code_tract')\n\nggplot() +\n  geom_sf(data = bh_tracts, aes(fill = income_pc), color=NA) +\n  geom_sf(data = muni_bh, color='gray10', fill=NA) +\n  labs(subtitle = 'Avgerage income per capita.\\nBelo Horizonte, 2010') +\n  scale_fill_viridis_c(name = \"Income per\\ncapita (R$)\",\n                       labels = scales::number_format(),\n                       option = 'cividis',\n                       breaks = c(0, 500, 1e3, 5e3, 1e4, 2e4),\n                       trans = \"pseudo_log\", na.value = \"gray90\") +\n  theme_void()",
    "crumbs": [
      "5. Agregados dos Setores Censitários"
    ]
  },
  {
    "objectID": "5_agregados_setores.html#example-2",
    "href": "5_agregados_setores.html#example-2",
    "title": "5. Agregados dos Setores Censitários",
    "section": "Example 2:",
    "text": "Example 2:\nIn this second example, we are going to map the proportion of households with the presence of trees in their surroundings. To do this, we need to download the \"Entorno\" dataset and sum the variables entorno01_V044 + entorno01_V046 + entorno01_V048.\n\n# download data\ntract_entorno &lt;- read_tracts(year = 2010,\n                             dataset = \"Entorno\", \n                             showProgress = FALSE)\n\nReading data cached locally.\n\n# filter observations and calculate indicator\ndf_trees &lt;- tract_entorno |&gt;\n                  filter(code_tract %in% tracts_sf$code_tract) |&gt;\n                  mutate(total_households = entorno01_V001,\n                         trees = entorno01_V044 + entorno01_V046 + entorno01_V048,\n                         trees_prop = trees / total_households) |&gt;\n                  select(code_tract, total_households, trees, trees_prop) |&gt;\n                  collect()\n\nhead(df_trees)\n\n        code_tract total_households trees trees_prop\n            &lt;char&gt;            &lt;num&gt; &lt;num&gt;      &lt;num&gt;\n1: 310620005620001              212   212  1.0000000\n2: 310620005620002              189   189  1.0000000\n3: 310620005620003              295   291  0.9864407\n4: 310620005620004              226   200  0.8849558\n5: 310620005620005              295   295  1.0000000\n6: 310620005620006              301   299  0.9933555\n\n\nNow we can merge the spatial data with our indicator and see how the presence of trees in the surroundings of households varies spatially.\n\nbh_tracts &lt;- left_join(tracts_sf, df_trees, by = 'code_tract')\n\nggplot() +\n  geom_sf(data = bh_tracts, aes(fill = trees_prop), color=NA) +\n  geom_sf(data = muni_bh, color='gray10', fill=NA) +\n  labs(subtitle = 'Share of households with trees in their surroundings.\\nBelo Horizonte, 2010') +\n  scale_fill_distiller(palette = \"Greens\", direction = 1, \n                       name='Share of\\nhouseholds', \n                       na.value = \"gray90\",\n                       labels = scales::percent) +\n  theme_void()",
    "crumbs": [
      "5. Agregados dos Setores Censitários"
    ]
  }
]